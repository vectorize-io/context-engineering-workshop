{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Groq API Overview - Interacting with LLMs on the Groq Platform\n",
        "\n",
        "This notebook provides a comprehensive guide to using the Groq API for LLM interactions, covering:\n",
        "1. Basic chat calls\n",
        "2. Conversational messaging with message history\n",
        "3. Function calling capabilities\n",
        "\n",
        "**Note**: This notebook is optimized for Google Colab but works in any Jupyter environment.\n",
        "\n",
        "Get your API key from: https://console.groq.com/keys"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Installation"
      ],
      "metadata": {
        "id": "setup-title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (run this cell first in Colab)\n",
        "!pip install groq\n",
        "\n",
        "print(\"✅ Packages installed successfully!\")"
      ],
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcd82d4-5c7c-480b-d41d-f4420144918c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.32.0\n",
            "✅ Packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import math\n",
        "\n",
        "# Import Groq after installation\n",
        "try:\n",
        "    from groq import Groq\n",
        "    print(\"✅ Groq imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(\"❌ Error importing Groq. Make sure you ran the installation cell above.\")\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2b9ae7-b3f3-44c0-e665-9f0f19f91fc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Groq imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Key Setup\n",
        "\n",
        "For Google Colab, we'll use Colab's built-in secrets management or direct input:"
      ],
      "metadata": {
        "id": "api-key-title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab API Key Setup\n",
        "import getpass\n",
        "\n",
        "# Method 1: Use Colab Secrets (Recommended)\n",
        "# Go to the key icon in the left sidebar and add GROQ_API_KEY\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_key = userdata.get('GROQ_API_KEY')\n",
        "    print(\"✅ API key loaded from Colab secrets\")\n",
        "except:\n",
        "    # Method 2: Direct input (less secure, but works)\n",
        "    print(\"Colab secrets not found. Please enter your API key:\")\n",
        "    print(\"Get your API key from: https://console.groq.com/keys\")\n",
        "    api_key = getpass.getpass(\"Enter your Groq API key: \")\n",
        "\n",
        "# Initialize the Groq client\n",
        "try:\n",
        "    client = Groq(api_key=api_key)\n",
        "    print(\"✅ Groq client initialized successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error initializing Groq client: {e}\")\n",
        "    print(\"Please check your API key and try again.\")"
      ],
      "metadata": {
        "id": "api-setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befeddf3-3299-4324-ce47-862c5131f57a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab secrets not found. Please enter your API key:\n",
            "Get your API key from: https://console.groq.com/keys\n",
            "Enter your Groq API key: ··········\n",
            "✅ Groq client initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 1: Basic Chat Call - Simple Request and Response\n",
        "\n",
        "Let's start with the simplest way to interact with a Groq LLM - a single request and response."
      ],
      "metadata": {
        "id": "part1-title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_chat(user_message, model=\"llama-3.3-70b-versatile\"):\n",
        "    \"\"\"\n",
        "    Simple chat function that sends a message and gets a response\n",
        "\n",
        "    Args:\n",
        "        user_message (str): The message to send to the LLM\n",
        "        model (str): The model to use (default: llama-3.3-70b-versatile)\n",
        "\n",
        "    Returns:\n",
        "        str: The LLM's response\n",
        "    \"\"\"\n",
        "    try:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": user_message,\n",
        "                }\n",
        "            ],\n",
        "            model=model,\n",
        "        )\n",
        "\n",
        "        return chat_completion.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Example usage\n",
        "print(\"=== Basic Chat Example ===\")\n",
        "user_input = \"What are some of the best movies of all time\"\n",
        "response = basic_chat(user_input)\n",
        "print(f\"User: {user_input}\")\n",
        "print(f\"Assistant: {response}\")"
      ],
      "metadata": {
        "id": "basic-chat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c959b44-f090-4d70-dbd0-154f7e199461"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Basic Chat Example ===\n",
            "User: What are some of the best movies of all time\n",
            "Assistant: Here's a list of some of the most iconic and influential movies of all time, across various genres:\n",
            "\n",
            "**Classics:**\n",
            "\n",
            "1. **The Godfather (1972)** - a crime drama directed by Francis Ford Coppola\n",
            "2. **The Shawshank Redemption (1994)** - a drama directed by Frank Darabont\n",
            "3. **The Wizard of Oz (1939)** - a musical fantasy film directed by Victor Fleming\n",
            "4. **Casablanca (1942)** - a romantic drama directed by Michael Curtiz\n",
            "5. **2001: A Space Odyssey (1968)** - a science fiction film directed by Stanley Kubrick\n",
            "\n",
            "**Sci-Fi and Fantasy:**\n",
            "\n",
            "1. **Star Wars: Episode IV - A New Hope (1977)** - a space opera directed by George Lucas\n",
            "2. **The Lord of the Rings: The Fellowship of the Ring (2001)** - a fantasy adventure film directed by Peter Jackson\n",
            "3. **Blade Runner (1982)** - a science fiction film directed by Ridley Scott\n",
            "4. **The Matrix (1999)** - a science fiction film directed by the Wachowskis\n",
            "5. **E.T. the Extra-Terrestrial (1982)** - a science fiction film directed by Steven Spielberg\n",
            "\n",
            "**Action and Adventure:**\n",
            "\n",
            "1. **Indiana Jones and the Raiders of the Lost Ark (1981)** - an action-adventure film directed by Steven Spielberg\n",
            "2. **The Dark Knight (2008)** - a superhero thriller directed by Christopher Nolan\n",
            "3. **Pulp Fiction (1994)** - a crime film directed by Quentin Tarantino\n",
            "4. **The Terminator (1984)** - a science fiction action film directed by James Cameron\n",
            "5. **Die Hard (1988)** - an action film directed by John McTiernan\n",
            "\n",
            "**Comedies:**\n",
            "\n",
            "1. **The Big Lebowski (1998)** - a comedy film directed by the Coen brothers\n",
            "2. **Monty Python and the Holy Grail (1975)** - a comedy film directed by Terry Gilliam and Terry Jones\n",
            "3. **Airplane! (1980)** - a parody film directed by Jim Abrahams, David Zucker, and Jerry Zucker\n",
            "4. **The Hangover (2009)** - a comedy film directed by Todd Phillips\n",
            "5. **Groundhog Day (1993)** - a comedy film directed by Harold Ramis\n",
            "\n",
            "**Dramas:**\n",
            "\n",
            "1. **12 Years a Slave (2013)** - a historical drama film directed by Steve McQueen\n",
            "2. **Schindler's List (1993)** - a historical drama film directed by Steven Spielberg\n",
            "3. **The Social Network (2010)** - a biographical drama film directed by David Fincher\n",
            "4. **The Pursuit of Happyness (2006)** - a biographical drama film directed by Gabriele Muccino\n",
            "5. **Million Dollar Baby (2004)** - a sports drama film directed by Clint Eastwood\n",
            "\n",
            "**Romance:**\n",
            "\n",
            "1. **Titanic (1997)** - a romantic epic disaster film directed by James Cameron\n",
            "2. **The Notebook (2004)** - a romantic drama film directed by Nick Cassavetes\n",
            "3. **Casablanca (1942)** - a romantic drama film directed by Michael Curtiz\n",
            "4. **When Harry Met Sally (1989)** - a romantic comedy film directed by Rob Reiner\n",
            "5. **La La Land (2016)** - a romantic musical film directed by Damien Chazelle\n",
            "\n",
            "Note: This is not an exhaustive list, and opinions on the \"best\" movies of all time vary depending on personal taste and cultural context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 2: Chat with Message Stack - Conversational AI\n",
        "\n",
        "For more natural conversations, we need to maintain a message history that gets updated as the conversation progresses."
      ],
      "metadata": {
        "id": "part2-title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GroqConversation:\n",
        "    \"\"\"\n",
        "    A class to manage conversational interactions with Groq LLMs\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model=\"llama-3.3-70b-versatile\", system_prompt=None):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.messages = []\n",
        "\n",
        "        # Add system prompt if provided\n",
        "        if system_prompt:\n",
        "            self.messages.append({\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            })\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        \"\"\"Add a message to the conversation history\"\"\"\n",
        "        self.messages.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content\n",
        "        })\n",
        "\n",
        "    def send_message(self, user_message):\n",
        "        \"\"\"\n",
        "        Send a user message and get the assistant's response\n",
        "\n",
        "        Args:\n",
        "            user_message (str): The user's message\n",
        "\n",
        "        Returns:\n",
        "            str: The assistant's response\n",
        "        \"\"\"\n",
        "        # Add user message to history\n",
        "        self.add_message(\"user\", user_message)\n",
        "\n",
        "        try:\n",
        "            # Get response from Groq\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=self.messages,\n",
        "                model=self.model,\n",
        "                temperature=0.7,\n",
        "                max_tokens=1000\n",
        "            )\n",
        "\n",
        "            # Extract assistant's response\n",
        "            assistant_response = chat_completion.choices[0].message.content\n",
        "\n",
        "            # Add assistant response to history\n",
        "            self.add_message(\"assistant\", assistant_response)\n",
        "\n",
        "            return assistant_response\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    def get_conversation_history(self):\n",
        "        \"\"\"Return the full conversation history\"\"\"\n",
        "        return self.messages\n",
        "\n",
        "    def clear_conversation(self, keep_system=True):\n",
        "        \"\"\"Clear conversation history, optionally keeping system prompt\"\"\"\n",
        "        if keep_system and self.messages and self.messages[0][\"role\"] == \"system\":\n",
        "            self.messages = [self.messages[0]]\n",
        "        else:\n",
        "            self.messages = []\n",
        "\n",
        "print(\"✅ GroqConversation class defined!\")"
      ],
      "metadata": {
        "id": "conversation-class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc03b97c-07bd-4f90-9841-58fcedbe62bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GroqConversation class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Creating a conversation with a system prompt\n",
        "print(\"=== Conversational Chat Example ===\")\n",
        "\n",
        "system_prompt = \"\"\"You are a helpful AI assistant with expertise in technology and science.\n",
        "You provide clear, accurate, and engaging explanations. Keep your responses concise but informative.\"\"\"\n",
        "\n",
        "conversation = GroqConversation(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    system_prompt=system_prompt\n",
        ")\n",
        "\n",
        "# Simulate a multi-turn conversation\n",
        "conversation_flow = [\n",
        "    \"What is machine learning?\",\n",
        "    \"Can you give me a specific example of how it's used in everyday life?\",\n",
        "    \"How does that differ from traditional programming?\"\n",
        "]\n",
        "\n",
        "for i, user_msg in enumerate(conversation_flow, 1):\n",
        "    print(f\"\\n--- Turn {i} ---\")\n",
        "    print(f\"User: {user_msg}\")\n",
        "\n",
        "    response = conversation.send_message(user_msg)\n",
        "    print(f\"Assistant: {response}\")\n",
        "\n",
        "# Show conversation history\n",
        "print(\"\\n=== Conversation Summary ===\")\n",
        "history = conversation.get_conversation_history()\n",
        "print(f\"Total messages in history: {len(history)}\")\n",
        "for i, msg in enumerate(history):\n",
        "    role = msg['role'].upper()\n",
        "    content_preview = msg['content'][:100] + \"...\" if len(msg['content']) > 100 else msg['content']\n",
        "    print(f\"{i+1}. {role}: {content_preview}\")"
      ],
      "metadata": {
        "id": "conversation-example",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5b2cb9-62f5-4f49-f557-c3645d4367da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Conversational Chat Example ===\n",
            "\n",
            "--- Turn 1 ---\n",
            "User: What is machine learning?\n",
            "Assistant: Machine learning is a subset of artificial intelligence (AI) that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed. It enables computers to improve their performance on a task over time, based on experience and data, rather than relying on pre-defined rules.\n",
            "\n",
            "--- Turn 2 ---\n",
            "User: Can you give me a specific example of how it's used in everyday life?\n",
            "Assistant: A common example is virtual assistants like Siri, Google Assistant, or Alexa. They use machine learning to recognize and improve their understanding of voice commands, allowing them to provide more accurate responses and personalized recommendations over time. For instance, if you frequently ask Siri to play a specific music genre, it will learn to prioritize those results in the future.\n",
            "\n",
            "--- Turn 3 ---\n",
            "User: How does that differ from traditional programming?\n",
            "Assistant: Traditional programming involves writing explicit rules and instructions for a computer to follow. In contrast, machine learning involves training a computer on data, allowing it to discover patterns and relationships, and make decisions based on that data. This means that machine learning systems can adapt and improve over time, whereas traditional programming requires manual updates and revisions to change the system's behavior.\n",
            "\n",
            "=== Conversation Summary ===\n",
            "Total messages in history: 7\n",
            "1. SYSTEM: You are a helpful AI assistant with expertise in technology and science. \n",
            "You provide clear, accurat...\n",
            "2. USER: What is machine learning?\n",
            "3. ASSISTANT: Machine learning is a subset of artificial intelligence (AI) that involves training algorithms to le...\n",
            "4. USER: Can you give me a specific example of how it's used in everyday life?\n",
            "5. ASSISTANT: A common example is virtual assistants like Siri, Google Assistant, or Alexa. They use machine learn...\n",
            "6. USER: How does that differ from traditional programming?\n",
            "7. ASSISTANT: Traditional programming involves writing explicit rules and instructions for a computer to follow. I...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 3: Function Calling - Tool Integration\n",
        "\n",
        "Function calling allows the LLM to use external tools and APIs to provide more accurate and up-to-date information."
      ],
      "metadata": {
        "id": "part3-title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some example functions that the LLM can call\n",
        "def calculate_area_circle(radius):\n",
        "    \"\"\"Calculate the area of a circle given its radius\"\"\"\n",
        "    if radius < 0:\n",
        "        return {\"error\": \"Radius cannot be negative\"}\n",
        "    area = math.pi * radius ** 2\n",
        "    return {\n",
        "        \"radius\": radius,\n",
        "        \"area\": round(area, 2),\n",
        "        \"formula\": \"π × r²\"\n",
        "    }\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"Get the current date and time\"\"\"\n",
        "    now = datetime.now()\n",
        "    return {\n",
        "        \"current_time\": now.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"timezone\": \"Local\",\n",
        "        \"day_of_week\": now.strftime(\"%A\"),\n",
        "        \"month\": now.strftime(\"%B\")\n",
        "    }\n",
        "\n",
        "def calculate_compound_interest(principal, rate, time, compound_frequency=1):\n",
        "    \"\"\"\n",
        "    Calculate compound interest\n",
        "\n",
        "    Args:\n",
        "        principal: Initial amount\n",
        "        rate: Annual interest rate (as decimal, e.g., 0.05 for 5%)\n",
        "        time: Time in years\n",
        "        compound_frequency: How many times interest is compounded per year\n",
        "    \"\"\"\n",
        "    amount = principal * (1 + rate/compound_frequency) ** (compound_frequency * time)\n",
        "    interest = amount - principal\n",
        "\n",
        "    return {\n",
        "        \"principal\": principal,\n",
        "        \"rate\": rate * 100,  # Convert to percentage\n",
        "        \"time_years\": time,\n",
        "        \"compound_frequency\": compound_frequency,\n",
        "        \"final_amount\": round(amount, 2),\n",
        "        \"interest_earned\": round(interest, 2)\n",
        "    }\n",
        "\n",
        "# Function registry - maps function names to actual functions\n",
        "AVAILABLE_FUNCTIONS = {\n",
        "    \"calculate_area_circle\": calculate_area_circle,\n",
        "    \"get_current_time\": get_current_time,\n",
        "    \"calculate_compound_interest\": calculate_compound_interest,\n",
        "}\n",
        "\n",
        "print(\"✅ Functions defined successfully!\")"
      ],
      "metadata": {
        "id": "functions-def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8229362-29f6-46c4-c606-d4733e6943bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Functions defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function definitions for the LLM (in the format Groq expects)\n",
        "function_definitions = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculate_area_circle\",\n",
        "            \"description\": \"Calculate the area of a circle given its radius\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"radius\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"The radius of the circle\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"radius\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_time\",\n",
        "            \"description\": \"Get the current date and time\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": []\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculate_compound_interest\",\n",
        "            \"description\": \"Calculate compound interest for an investment\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"principal\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Initial investment amount\"\n",
        "                    },\n",
        "                    \"rate\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Annual interest rate as a decimal (e.g., 0.05 for 5%)\"\n",
        "                    },\n",
        "                    \"time\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Investment time in years\"\n",
        "                    },\n",
        "                    \"compound_frequency\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Number of times interest is compounded per year (default: 1)\",\n",
        "                        \"default\": 1\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"principal\", \"rate\", \"time\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"✅ Function definitions created!\")"
      ],
      "metadata": {
        "id": "function-definitions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb167d6-8e92-4ce4-c259-8eaddc76d22d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Function definitions created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GroqFunctionCalling:\n",
        "    \"\"\"\n",
        "    A class to handle Groq conversations with function calling capabilities\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model=\"llama-3.3-70b-versatile\"):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.messages = []\n",
        "        self.functions = function_definitions\n",
        "        self.available_functions = AVAILABLE_FUNCTIONS\n",
        "\n",
        "    def send_message_with_functions(self, user_message):\n",
        "        \"\"\"\n",
        "        Send a message that can trigger function calls\n",
        "        \"\"\"\n",
        "        # Add user message\n",
        "        self.messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message\n",
        "        })\n",
        "\n",
        "        try:\n",
        "            # Make the initial request with function definitions\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=self.messages,\n",
        "                tools=self.functions,\n",
        "                tool_choice=\"auto\"  # Let the model decide when to use functions\n",
        "            )\n",
        "\n",
        "            response_message = response.choices[0].message\n",
        "\n",
        "            # Check if the model wants to call a function\n",
        "            if response_message.tool_calls:\n",
        "                # Add the assistant's response to messages\n",
        "                self.messages.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": response_message.content,\n",
        "                    \"tool_calls\": response_message.tool_calls\n",
        "                })\n",
        "\n",
        "                # Process each function call\n",
        "                for tool_call in response_message.tool_calls:\n",
        "                    function_name = tool_call.function.name\n",
        "\n",
        "                    # Safely parse function arguments\n",
        "                    try:\n",
        "                        function_args = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}\n",
        "                        # Handle case where function_args might be None or empty\n",
        "                        if function_args is None:\n",
        "                            function_args = {}\n",
        "                    except (json.JSONDecodeError, TypeError):\n",
        "                        function_args = {}\n",
        "\n",
        "                    print(f\"🔧 Calling function: {function_name}\")\n",
        "                    print(f\"📝 Arguments: {function_args}\")\n",
        "\n",
        "                    # Call the actual function\n",
        "                    if function_name in self.available_functions:\n",
        "                        function_result = self.available_functions[function_name](**function_args)\n",
        "\n",
        "                        # Add function result to messages\n",
        "                        self.messages.append({\n",
        "                            \"role\": \"tool\",\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": json.dumps(function_result)\n",
        "                        })\n",
        "\n",
        "                # Get the final response after function calls\n",
        "                final_response = self.client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    messages=self.messages,\n",
        "                )\n",
        "\n",
        "                final_message = final_response.choices[0].message.content\n",
        "                self.messages.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": final_message\n",
        "                })\n",
        "\n",
        "                return final_message\n",
        "\n",
        "            else:\n",
        "                # No function call needed, just return the response\n",
        "                self.messages.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": response_message.content\n",
        "                })\n",
        "                return response_message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "print(\"✅ GroqFunctionCalling class defined!\")"
      ],
      "metadata": {
        "id": "function-calling-class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9c8101-d0bb-47c7-a3cd-c6870fa9b2d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GroqFunctionCalling class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "print(\"=== Function Calling Examples ===\")\n",
        "\n",
        "function_chat = GroqFunctionCalling()\n",
        "\n",
        "# Test cases that should trigger different functions\n",
        "test_queries = [\n",
        "    \"What time is it right now?\",\n",
        "    \"Calculate the area of a circle with radius 5\",\n",
        "    \"If I invest $1000 at 5% annual interest for 3 years, how much will I have?\",\n",
        "    \"Hello, how are you today?\"  # This shouldn't trigger any functions\n",
        "]\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n--- Example {i} ---\")\n",
        "    print(f\"User: {query}\")\n",
        "\n",
        "    response = function_chat.send_message_with_functions(query)\n",
        "    print(f\"Assistant: {response}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "function-examples",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff18e687-eaaa-4c7c-fdb9-1984220845a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Function Calling Examples ===\n",
            "\n",
            "--- Example 1 ---\n",
            "User: What time is it right now?\n",
            "🔧 Calling function: get_current_time\n",
            "📝 Arguments: {}\n",
            "Assistant: The current time is 5:41:07 PM.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Example 2 ---\n",
            "User: Calculate the area of a circle with radius 5\n",
            "🔧 Calling function: calculate_area_circle\n",
            "📝 Arguments: {'radius': 5}\n",
            "Assistant: The area of a circle with radius 5 is 78.54 square units.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Example 3 ---\n",
            "User: If I invest $1000 at 5% annual interest for 3 years, how much will I have?\n",
            "🔧 Calling function: calculate_compound_interest\n",
            "📝 Arguments: {'principal': 1000, 'rate': 0.05, 'time': 3}\n",
            "Assistant: After 3 years, you will have $1157.63, earning $157.63 in interest.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Example 4 ---\n",
            "User: Hello, how are you today?\n",
            "Assistant: I'm just a language model, so I don't have feelings or emotions like humans do, but I'm here to help answer your questions and provide information to the best of my abilities. How can I assist you today?\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}